{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1845f8f0-f82c-42ac-9b21-2c2419f730a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9522debb-c0f1-4d0b-b42c-b664f3f382d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f61426-b96b-40bc-af8a-8d88a7c6178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: d2l 1.0.3\n",
      "Uninstalling d2l-1.0.3:\n",
      "  Would remove:\n",
      "    /home/akshatsrivastava/.local/lib/python3.10/site-packages/d2l-1.0.3.dist-info/*\n",
      "    /home/akshatsrivastava/.local/lib/python3.10/site-packages/d2l/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip3 uninstall d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e225153-08f9-4e38-a20a-d54a96e6be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38e9a1c1-8d69-42d8-a82b-3a9500dcb557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55cd2211-929a-4f02-8668-271f06950471",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4eef857-381d-4b13-b70c-befc6e9394d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b600842f-0eb5-40cb-8b84-7c1d34a5e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "##object edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deb19170-5e91-4ea8-94e5-121fdf9bea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0455237a-5c20-4b9b-83e1-dcd1d2faa9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "982f0863-ef51-4c81-a37c-206cd9531411",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aafc084c-5f5d-4e19-b352-257eaaf86f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58f4bfc7-bae9-41ee-91e7-c26fa937354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f869d9a-29cf-4801-8ee2-69de03787f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e91a0a-230c-4ffe-97b0-a7d08c1e5d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa19c1-4eb1-4114-933c-35498ddfb869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae5dbfe-a8de-4d3c-b418-6e9e0ee6c109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aad1d8fb-7be7-4fcd-a3ee-ac5c198853ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8830889c-c71b-42d1-bb5a-9196bc63689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 18.456\n",
      "epoch 4, loss 6.564\n",
      "epoch 6, loss 2.522\n",
      "epoch 8, loss 1.005\n",
      "epoch 10, loss 0.407\n"
     ]
    }
   ],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
    "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# The two-dimensional convolutional layer uses four-dimensional input and\n",
    "# output in the format of (example, channel, height, width), where the batch\n",
    "# size (number of examples in the batch) and the number of channels are both 1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # Learning rate\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17034f6b-00cf-407b-ad23-af4a0d898054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0551, -0.9238]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a415bf86-c41a-4a39-ab78-20d7c3c720e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7.2.5. Cross-Correlation and ConvolutionÂ¶\n",
    "## Padding and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e706ef4-8c73-4a57-992a-e37c5e321847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d9254db-a756-4320-9555-4f89f2b66941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We define a helper function to calculate convolutions. It initializes the\n",
    "# convolutional layer weights and performs corresponding dimensionality\n",
    "# elevations and reductions on the input and output\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Strip the first two dimensions: examples and channels\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
    "# are added\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e5daa-d569-4ef8-a806-f3bc1c021f3e",
   "metadata": {},
   "source": [
    "## Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da779a9e-3015-4778-8b25-8bc55b655e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac3009b1-e74b-4852-9229-d3374823c0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bd795-c77c-4383-ade0-ea8d47897da4",
   "metadata": {},
   "source": [
    "## Multiple input and output channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "241431c9-4e6d-4a47-a5d8-a0c7f25e4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49d410e9-e5bb-4c9e-8ee3-801bb601cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X,K):\n",
    "    return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce0d9cf3-aade-442f-bf8e-a4ff9a16b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc0085df-a04e-4119-be1b-ef35ef9fd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MUltiple Output channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97628588-1ad2-4690-9045-624ee26fc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of K, and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c0d52f2-18b6-4ced-b545-12676e5b67d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "badaedd7-f0b2-4b29-9cc1-75b2c2c6272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee8a2809-6dfe-40d8-bf10-d60ba9d8d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1x 1 conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1effcfb3-8317-40ca-9771-b380f4b51303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2633ebc-f36b-4c46-84f9-9027e181a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "415718b1-e7cc-4532-8562-bc80ce4fd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79c6c466-837c-4dfa-b5ec-25361e9d73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4bc79862-07e0-44a6-ac06-2a967f3b520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cd268ae-33aa-4287-b423-2b1a6ae23160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "529e812b-8cb5-47e6-be5c-7e333cdcd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d77e12cd-d6c5-404d-9593-eb2766ff96d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8c23a2a-7a46-4977-8849-6a39d51be6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "# Pooling has no model parameters, hence it needs no initialization\n",
    "pool2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60fd97b8-ad16-4039-b57b-f4182513cba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c112d4fb-e686-4d59-9e22-6467a76a22fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b3671-20c4-4d4e-a66d-27a3221e1c8e",
   "metadata": {},
   "source": [
    "## Multiple channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48d364ee-26ef-4d15-a454-42bd98975597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a479528-0367-448a-b72e-99379432a12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f06632-da2e-4514-8a40-10e459acf0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
